---
title: "Most popular running songs at 160 BPM"
author: "Louise Nyholm Jensen"
date: "2nd of November 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Goal
I want to be able to analyse the data on the most popular running songs at 160 BPM, which are summarised on https://jog.fm/workout-songs/at/160/bpm.160?order=desc&sort=popularity.


```{r libraries}
# loading libraries
pacman::p_load(rvest, tidyverse, janitor, statebins, ggplot2)
```

## Scrape the data

Next, learn how scrape the content of the website and extract the HTML table:
```{r}
url <- "https://jog.fm/workout-songs/at/160/bpm.160?order=desc&sort=popularity"
# scrape the website
url_html <- read_html(url)
```

Since I could not get data extraction to work on a more general tag, I decided to go to the cell level. Here, I extract individual cells from the HTML table by using the most unique tags, I can find (e.g. "div.top" for the artist, "div.title" for the song_title, "div.meta" for the genre) - and in some cases, I go (through piping) further into that tag in order to get to a tag, which is not unique overall, but only in combination with its former/parent tag.
This creates a character element out of each table cell, which is why I have to do some extra data cleaning. See below

```{r}
# Accessing the relevant information
artist <- url_html %>% 
	html_nodes("div.top") %>% 
	html_text(trim = FALSE)
head(artist)

song_title <- url_html %>%
	html_nodes("div.title") %>%
	html_text(trim = FALSE)
head(song_title)

genre <- url_html %>%
	html_nodes("div.meta") %>%
	html_nodes("a") %>% 
	html_text(trim = FALSE)
head(genre)

BPM <- url_html %>%
	html_nodes("div.side-box.fixed") %>%
	html_nodes("div.middle") %>% 
	html_text(trim = FALSE)
head(BPM)

pace <- url_html %>%
	html_nodes("div.side-box") %>%
	html_nodes("div.middle") %>% 
	html_text(trim = FALSE)
head(pace)

# Cleaning the strings with > 24 observations (there are only 24 songs on this page)
# genre
length(genre) # 4x as many observations
genre # inspecting - and noticing that music services are here

# removing the irrelevant information
genre <- genre %>% .[.!="Apple Music" & .!="Spotify" & .!="Amazon Music"]

length(genre) # checking length again - now 24

# pace
length(pace) # 2x as many observations
pace # inspecting - and noticing that BPM are also here

# Extracting only the paces (pattern: one or two digits, colon, two digits)
pace <- pace %>% str_extract("\\d+:\\d{2}")
pace <- na.omit(pace) # removing NAs (the former BPMs)

length(pace) # checking length again - now 24

# Putting data together in a dataframe
df_run <- tibble(artist, song_title, genre, BPM, pace)
df_run$BPM <- as.numeric(df_run$BPM) # making BPM numeric
```
Now I'm done with the scraping and have the data in a dataframe.

## Visualisation!

What are the most common genres on the top 24 most popular running songs at 160 BPM?
```{r}
ggplot(df_run) +
	geom_bar(aes(x = genre, fill = genre)) +
	xlab("Genre") +
	ylab("Count") +
	labs(subtitle = "Which genre(s) is/are most common on the top 24 most popular running songs at 160 BPM?")

```

Based on this, it seems that pop, rock, and alternative music are the most popular genres on the top 24 running hits at 160 BPM.